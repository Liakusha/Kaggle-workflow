{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77d3d6e-d7d9-461e-9254-29d3d20be837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfc539e-1f30-4d57-bd3f-f6c458b3526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = Path(\"C:/ML_Projects/kaggle-workflow/data/\")\n",
    "OUTPUT_PATH = Path(\"C:/ML_Projects/kaggle-workflow/output/\")\n",
    "\n",
    "# General settings\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Metric choice placeholder\n",
    "#Adjust depending on the competition\n",
    "METRIC = \"auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a49f185-a31f-41cb-be27-ccbbb03d8b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape, test shape:\n",
      "(700000, 26) (300000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.93</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Current</td>\n",
       "      <td>Employed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Upper-Middle</td>\n",
       "      <td>Never</td>\n",
       "      <td>Employed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Never</td>\n",
       "      <td>Retired</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.83</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Current</td>\n",
       "      <td>Employed</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Upper-Middle</td>\n",
       "      <td>Never</td>\n",
       "      <td>Retired</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age  alcohol_consumption_per_week  physical_activity_minutes_per_week  \\\n",
       "0   0   31                             1                                  45   \n",
       "1   1   50                             2                                  73   \n",
       "2   2   32                             3                                 158   \n",
       "3   3   54                             3                                  77   \n",
       "4   4   54                             1                                  55   \n",
       "\n",
       "   diet_score  sleep_hours_per_day  screen_time_hours_per_day   bmi  \\\n",
       "0         7.7                  6.8                        6.1  33.4   \n",
       "1         5.7                  6.5                        5.8  23.8   \n",
       "2         8.5                  7.4                        9.1  24.1   \n",
       "3         4.6                  7.0                        9.2  26.6   \n",
       "4         5.7                  6.2                        5.1  28.8   \n",
       "\n",
       "   waist_to_hip_ratio  systolic_bp  ...  gender  ethnicity  education_level  \\\n",
       "0                0.93          112  ...  Female   Hispanic       Highschool   \n",
       "1                0.83          120  ...  Female      White       Highschool   \n",
       "2                0.83           95  ...    Male   Hispanic       Highschool   \n",
       "3                0.83          121  ...  Female      White       Highschool   \n",
       "4                0.90          108  ...    Male      White       Highschool   \n",
       "\n",
       "   income_level  smoking_status  employment_status family_history_diabetes  \\\n",
       "0  Lower-Middle         Current           Employed                       0   \n",
       "1  Upper-Middle           Never           Employed                       0   \n",
       "2  Lower-Middle           Never            Retired                       0   \n",
       "3  Lower-Middle         Current           Employed                       0   \n",
       "4  Upper-Middle           Never            Retired                       0   \n",
       "\n",
       "  hypertension_history cardiovascular_history diagnosed_diabetes  \n",
       "0                    0                      0                1.0  \n",
       "1                    0                      0                1.0  \n",
       "2                    0                      0                0.0  \n",
       "3                    1                      0                1.0  \n",
       "4                    1                      0                1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "#Load Data\n",
    "train = pd.read_csv(DATA_PATH / \"Diabetes Prediction Challenge\" / \"train.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"Diabetes Prediction Challenge\" / \"test.csv\")\n",
    "\n",
    "# DISPLAY DATA\n",
    "print(\"Train shape, test shape:\")\n",
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c929598-b07a-49e3-a31e-d74b9b6fe3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df.rename(columns = ({\"alcohol_consumption_per_week\":\"alc\",'physical_activity_minutes_per_week':\"activity\", 'diet_score':\"diet\",\n",
    "                          'sleep_hours_per_day': \"sleep\", 'screen_time_hours_per_day':\"screen\", 'education_level':\"edu\",\n",
    "                           'income_level':\"inc\", 'smoking_status': \"smoke\", 'employment_status':\"empl\", 'family_history_diabetes': \"fam_his\",\n",
    "                          'hypertension_history': \"hyp_his\", 'cardiovascular_history': \"card_his\", 'diagnosed_diabetes': \"label\"} ), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc89d2d-6347-4e86-b361-09b9e5b8f641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>alc</th>\n",
       "      <th>activity</th>\n",
       "      <th>diet</th>\n",
       "      <th>sleep</th>\n",
       "      <th>screen</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>edu</th>\n",
       "      <th>inc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>empl</th>\n",
       "      <th>fam_his</th>\n",
       "      <th>hyp_his</th>\n",
       "      <th>card_his</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.93</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Current</td>\n",
       "      <td>Employed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Upper-Middle</td>\n",
       "      <td>Never</td>\n",
       "      <td>Employed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Never</td>\n",
       "      <td>Retired</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.83</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Current</td>\n",
       "      <td>Employed</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Upper-Middle</td>\n",
       "      <td>Never</td>\n",
       "      <td>Retired</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age  alc  activity  diet  sleep  screen   bmi  waist_to_hip_ratio  \\\n",
       "0   0   31    1        45   7.7    6.8     6.1  33.4                0.93   \n",
       "1   1   50    2        73   5.7    6.5     5.8  23.8                0.83   \n",
       "2   2   32    3       158   8.5    7.4     9.1  24.1                0.83   \n",
       "3   3   54    3        77   4.6    7.0     9.2  26.6                0.83   \n",
       "4   4   54    1        55   5.7    6.2     5.1  28.8                0.90   \n",
       "\n",
       "   systolic_bp  ...  gender  ethnicity         edu           inc    smoke  \\\n",
       "0          112  ...  Female   Hispanic  Highschool  Lower-Middle  Current   \n",
       "1          120  ...  Female      White  Highschool  Upper-Middle    Never   \n",
       "2           95  ...    Male   Hispanic  Highschool  Lower-Middle    Never   \n",
       "3          121  ...  Female      White  Highschool  Lower-Middle  Current   \n",
       "4          108  ...    Male      White  Highschool  Upper-Middle    Never   \n",
       "\n",
       "       empl fam_his hyp_his card_his label  \n",
       "0  Employed       0       0        0   1.0  \n",
       "1  Employed       0       0        0   1.0  \n",
       "2   Retired       0       0        0   0.0  \n",
       "3  Employed       0       1        0   1.0  \n",
       "4   Retired       0       1        0   1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a90fe70-3a73-47fd-a95b-d5d9daafae7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'alc', 'activity', 'diet', 'sleep', 'screen', 'bmi',\n",
       "       'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate',\n",
       "       'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol',\n",
       "       'triglycerides', 'gender', 'ethnicity', 'edu', 'inc', 'smoke', 'empl',\n",
       "       'fam_his', 'hyp_his', 'card_his', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd55550-f3f6-47ef-bf3b-0f58acc9a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['age','activity','diet','sleep','screen','bmi',\n",
    "    'waist_to_hip_ratio','systolic_bp','diastolic_bp',\n",
    "    'heart_rate','cholesterol_total','hdl_cholesterol',\n",
    "    'ldl_cholesterol','triglycerides']\n",
    "TARGET = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e264af2-8536-44ed-9940-38b8634e788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ML_Projects\\kaggle-workflow\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print('TF Version',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090831b3-0672-42a7-833f-38d8f4110678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(size):\n",
    "    x_in = Input(shape=(size,))\n",
    "\n",
    "    x = Dense(32)(x_in)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"swish\")(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"swish\")(x)\n",
    "\n",
    "    x = Dense(32)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"swish\")(x)\n",
    "\n",
    "    # Binary classification → sigmoid\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs = x_in, outputs = x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34490626-2967-446c-92af-3b39ccac84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "def make_callbacks():\n",
    "    lr_callback = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    early_stop_cb = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return [lr_callback, early_stop_cb]\n",
    "\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840d3734-3d28-4495-886e-6305609505cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "########## Fold 1 ##########\n",
      "############################\n",
      "WARNING:tensorflow:From C:\\ML_Projects\\kaggle-workflow\\venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6458 - loss: 0.6305 - val_auc: 0.6527 - val_loss: 0.6268 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6512 - loss: 0.6275 - val_auc: 0.6523 - val_loss: 0.6270 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6518 - loss: 0.6271 - val_auc: 0.6536 - val_loss: 0.6263 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6521 - loss: 0.6269 - val_auc: 0.6540 - val_loss: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6526 - loss: 0.6266 - val_auc: 0.6542 - val_loss: 0.6258 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6528 - loss: 0.6266 - val_auc: 0.6544 - val_loss: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6530 - loss: 0.6264 - val_auc: 0.6540 - val_loss: 0.6259 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6539 - loss: 0.6260 - val_auc: 0.6543 - val_loss: 0.6257 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6539 - loss: 0.6259 - val_auc: 0.6542 - val_loss: 0.6256 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6538 - loss: 0.6260 - val_auc: 0.6542 - val_loss: 0.6255 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6540 - loss: 0.6259 - val_auc: 0.6544 - val_loss: 0.6256 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6540 - loss: 0.6259 - val_auc: 0.6542 - val_loss: 0.6255 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6541 - loss: 0.6258 - val_auc: 0.6544 - val_loss: 0.6255 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6546 - loss: 0.6255 - val_auc: 0.6545 - val_loss: 0.6254 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6546 - loss: 0.6255 - val_auc: 0.6544 - val_loss: 0.6255 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6545 - loss: 0.6255 - val_auc: 0.6543 - val_loss: 0.6255 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6547 - loss: 0.6254 - val_auc: 0.6544 - val_loss: 0.6254 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6550 - loss: 0.6253 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 1.2500e-04\n",
      "Epoch 19/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6549 - loss: 0.6253 - val_auc: 0.6544 - val_loss: 0.6253 - learning_rate: 1.2500e-04\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6551 - loss: 0.6252 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 1.2500e-04\n",
      "Epoch 21/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6552 - loss: 0.6252 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 6.2500e-05\n",
      "Epoch 22/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6554 - loss: 0.6251 - val_auc: 0.6544 - val_loss: 0.6254 - learning_rate: 6.2500e-05\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6553 - loss: 0.6251 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 6.2500e-05\n",
      "Epoch 24/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6552 - loss: 0.6252 - val_auc: 0.6544 - val_loss: 0.6254 - learning_rate: 3.1250e-05\n",
      "Epoch 25/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6553 - loss: 0.6251 - val_auc: 0.6544 - val_loss: 0.6254 - learning_rate: 3.1250e-05\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6553 - loss: 0.6251 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 3.1250e-05\n",
      "Epoch 27/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6555 - loss: 0.6250 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 1.5625e-05\n",
      "Epoch 28/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6554 - loss: 0.6250 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 1.5625e-05\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6552 - loss: 0.6251 - val_auc: 0.6543 - val_loss: 0.6254 - learning_rate: 1.5625e-05\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Fold 1 AUC: 0.65448\n",
      "\n",
      "############################\n",
      "########## Fold 2 ##########\n",
      "############################\n",
      "Epoch 1/100\n",
      "2188/2188 - 8s - 4ms/step - auc: 0.6447 - loss: 0.6312 - val_auc: 0.6523 - val_loss: 0.6270 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6510 - loss: 0.6275 - val_auc: 0.6535 - val_loss: 0.6263 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6519 - loss: 0.6270 - val_auc: 0.6535 - val_loss: 0.6265 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6524 - loss: 0.6266 - val_auc: 0.6533 - val_loss: 0.6263 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6527 - loss: 0.6265 - val_auc: 0.6542 - val_loss: 0.6260 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6529 - loss: 0.6264 - val_auc: 0.6544 - val_loss: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6532 - loss: 0.6262 - val_auc: 0.6545 - val_loss: 0.6256 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6533 - loss: 0.6262 - val_auc: 0.6539 - val_loss: 0.6260 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6534 - loss: 0.6261 - val_auc: 0.6543 - val_loss: 0.6258 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6541 - loss: 0.6257 - val_auc: 0.6543 - val_loss: 0.6257 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6542 - loss: 0.6256 - val_auc: 0.6546 - val_loss: 0.6257 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6543 - loss: 0.6256 - val_auc: 0.6546 - val_loss: 0.6258 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6547 - loss: 0.6253 - val_auc: 0.6548 - val_loss: 0.6256 - learning_rate: 2.5000e-04\n",
      "Epoch 14/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6549 - loss: 0.6252 - val_auc: 0.6548 - val_loss: 0.6255 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6549 - loss: 0.6253 - val_auc: 0.6546 - val_loss: 0.6256 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6550 - loss: 0.6252 - val_auc: 0.6548 - val_loss: 0.6255 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "2188/2188 - 5s - 2ms/step - auc: 0.6551 - loss: 0.6251 - val_auc: 0.6548 - val_loss: 0.6255 - learning_rate: 1.2500e-04\n",
      "Epoch 18/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6552 - loss: 0.6250 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 1.2500e-04\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6553 - loss: 0.6250 - val_auc: 0.6548 - val_loss: 0.6255 - learning_rate: 1.2500e-04\n",
      "Epoch 20/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6554 - loss: 0.6250 - val_auc: 0.6548 - val_loss: 0.6254 - learning_rate: 6.2500e-05\n",
      "Epoch 21/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6555 - loss: 0.6249 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 6.2500e-05\n",
      "Epoch 22/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6554 - loss: 0.6249 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 6.2500e-05\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6556 - loss: 0.6249 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 6.2500e-05\n",
      "Epoch 24/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6555 - loss: 0.6249 - val_auc: 0.6548 - val_loss: 0.6255 - learning_rate: 3.1250e-05\n",
      "Epoch 25/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6556 - loss: 0.6248 - val_auc: 0.6548 - val_loss: 0.6255 - learning_rate: 3.1250e-05\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6555 - loss: 0.6249 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 3.1250e-05\n",
      "Epoch 27/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6556 - loss: 0.6248 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 1.5625e-05\n",
      "Epoch 28/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6557 - loss: 0.6248 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 1.5625e-05\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6557 - loss: 0.6248 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 1.5625e-05\n",
      "Epoch 30/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6557 - loss: 0.6248 - val_auc: 0.6547 - val_loss: 0.6255 - learning_rate: 7.8125e-06\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Fold 2 AUC: 0.65481\n",
      "\n",
      "############################\n",
      "########## Fold 3 ##########\n",
      "############################\n",
      "Epoch 1/100\n",
      "2188/2188 - 9s - 4ms/step - auc: 0.6438 - loss: 0.6320 - val_auc: 0.6503 - val_loss: 0.6284 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6515 - loss: 0.6272 - val_auc: 0.6514 - val_loss: 0.6276 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6520 - loss: 0.6270 - val_auc: 0.6513 - val_loss: 0.6274 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6528 - loss: 0.6266 - val_auc: 0.6518 - val_loss: 0.6271 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6529 - loss: 0.6265 - val_auc: 0.6526 - val_loss: 0.6267 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6534 - loss: 0.6262 - val_auc: 0.6527 - val_loss: 0.6266 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6534 - loss: 0.6262 - val_auc: 0.6526 - val_loss: 0.6268 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6537 - loss: 0.6260 - val_auc: 0.6527 - val_loss: 0.6267 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6539 - loss: 0.6259 - val_auc: 0.6530 - val_loss: 0.6266 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6546 - loss: 0.6255 - val_auc: 0.6531 - val_loss: 0.6262 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6547 - loss: 0.6255 - val_auc: 0.6532 - val_loss: 0.6263 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6548 - loss: 0.6253 - val_auc: 0.6526 - val_loss: 0.6265 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2188/2188 - 11s - 5ms/step - auc: 0.6548 - loss: 0.6253 - val_auc: 0.6529 - val_loss: 0.6263 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6554 - loss: 0.6251 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6555 - loss: 0.6249 - val_auc: 0.6531 - val_loss: 0.6262 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6556 - loss: 0.6249 - val_auc: 0.6529 - val_loss: 0.6263 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6557 - loss: 0.6248 - val_auc: 0.6531 - val_loss: 0.6262 - learning_rate: 1.2500e-04\n",
      "Epoch 18/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6558 - loss: 0.6248 - val_auc: 0.6531 - val_loss: 0.6262 - learning_rate: 1.2500e-04\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6559 - loss: 0.6248 - val_auc: 0.6530 - val_loss: 0.6262 - learning_rate: 1.2500e-04\n",
      "Epoch 20/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6560 - loss: 0.6247 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 6.2500e-05\n",
      "Epoch 21/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6559 - loss: 0.6247 - val_auc: 0.6530 - val_loss: 0.6262 - learning_rate: 6.2500e-05\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 6.2500e-05\n",
      "Epoch 23/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 3.1250e-05\n",
      "Epoch 24/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 3.1250e-05\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6562 - loss: 0.6246 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 3.1250e-05\n",
      "Epoch 26/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 1.5625e-05\n",
      "Epoch 27/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6562 - loss: 0.6246 - val_auc: 0.6530 - val_loss: 0.6263 - learning_rate: 1.5625e-05\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 3 AUC: 0.65310\n",
      "\n",
      "############################\n",
      "########## Fold 4 ##########\n",
      "############################\n",
      "Epoch 1/100\n",
      "2188/2188 - 9s - 4ms/step - auc: 0.6452 - loss: 0.6309 - val_auc: 0.6508 - val_loss: 0.6279 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6518 - loss: 0.6271 - val_auc: 0.6496 - val_loss: 0.6290 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6525 - loss: 0.6267 - val_auc: 0.6510 - val_loss: 0.6278 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6529 - loss: 0.6265 - val_auc: 0.6520 - val_loss: 0.6273 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6531 - loss: 0.6263 - val_auc: 0.6518 - val_loss: 0.6274 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6535 - loss: 0.6262 - val_auc: 0.6516 - val_loss: 0.6270 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6536 - loss: 0.6261 - val_auc: 0.6519 - val_loss: 0.6269 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6538 - loss: 0.6260 - val_auc: 0.6520 - val_loss: 0.6270 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6539 - loss: 0.6259 - val_auc: 0.6521 - val_loss: 0.6269 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6541 - loss: 0.6258 - val_auc: 0.6521 - val_loss: 0.6272 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6546 - loss: 0.6254 - val_auc: 0.6527 - val_loss: 0.6266 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6548 - loss: 0.6254 - val_auc: 0.6527 - val_loss: 0.6268 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6548 - loss: 0.6254 - val_auc: 0.6527 - val_loss: 0.6266 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6550 - loss: 0.6252 - val_auc: 0.6524 - val_loss: 0.6268 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6553 - loss: 0.6250 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "2188/2188 - 10s - 5ms/step - auc: 0.6555 - loss: 0.6250 - val_auc: 0.6527 - val_loss: 0.6266 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6556 - loss: 0.6249 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6556 - loss: 0.6249 - val_auc: 0.6528 - val_loss: 0.6265 - learning_rate: 1.2500e-04\n",
      "Epoch 19/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6557 - loss: 0.6248 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 1.2500e-04\n",
      "Epoch 20/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6558 - loss: 0.6248 - val_auc: 0.6525 - val_loss: 0.6265 - learning_rate: 1.2500e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6559 - loss: 0.6248 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 1.2500e-04\n",
      "Epoch 22/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6559 - loss: 0.6248 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 6.2500e-05\n",
      "Epoch 23/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6560 - loss: 0.6247 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 6.2500e-05\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6560 - loss: 0.6247 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 6.2500e-05\n",
      "Epoch 25/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 3.1250e-05\n",
      "Epoch 26/100\n",
      "2188/2188 - 8s - 4ms/step - auc: 0.6559 - loss: 0.6247 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 3.1250e-05\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 3.1250e-05\n",
      "Epoch 28/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6527 - val_loss: 0.6265 - learning_rate: 1.5625e-05\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 4 AUC: 0.65281\n",
      "\n",
      "############################\n",
      "########## Fold 5 ##########\n",
      "############################\n",
      "Epoch 1/100\n",
      "2188/2188 - 9s - 4ms/step - auc: 0.6467 - loss: 0.6298 - val_auc: 0.6509 - val_loss: 0.6279 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6511 - loss: 0.6274 - val_auc: 0.6525 - val_loss: 0.6267 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6521 - loss: 0.6268 - val_auc: 0.6526 - val_loss: 0.6267 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6526 - loss: 0.6266 - val_auc: 0.6528 - val_loss: 0.6267 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6529 - loss: 0.6264 - val_auc: 0.6534 - val_loss: 0.6263 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6533 - loss: 0.6262 - val_auc: 0.6530 - val_loss: 0.6264 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6533 - loss: 0.6261 - val_auc: 0.6537 - val_loss: 0.6261 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6536 - loss: 0.6260 - val_auc: 0.6535 - val_loss: 0.6262 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6538 - loss: 0.6260 - val_auc: 0.6532 - val_loss: 0.6264 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6539 - loss: 0.6259 - val_auc: 0.6541 - val_loss: 0.6259 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6540 - loss: 0.6258 - val_auc: 0.6536 - val_loss: 0.6263 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6542 - loss: 0.6256 - val_auc: 0.6541 - val_loss: 0.6261 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6542 - loss: 0.6257 - val_auc: 0.6541 - val_loss: 0.6259 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6547 - loss: 0.6253 - val_auc: 0.6542 - val_loss: 0.6258 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6549 - loss: 0.6252 - val_auc: 0.6542 - val_loss: 0.6259 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6550 - loss: 0.6252 - val_auc: 0.6538 - val_loss: 0.6260 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6554 - loss: 0.6249 - val_auc: 0.6542 - val_loss: 0.6257 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6554 - loss: 0.6249 - val_auc: 0.6543 - val_loss: 0.6259 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6555 - loss: 0.6249 - val_auc: 0.6542 - val_loss: 0.6258 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6556 - loss: 0.6248 - val_auc: 0.6539 - val_loss: 0.6259 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6558 - loss: 0.6247 - val_auc: 0.6540 - val_loss: 0.6259 - learning_rate: 1.2500e-04\n",
      "Epoch 22/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6557 - loss: 0.6247 - val_auc: 0.6540 - val_loss: 0.6259 - learning_rate: 1.2500e-04\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6560 - loss: 0.6247 - val_auc: 0.6540 - val_loss: 0.6259 - learning_rate: 1.2500e-04\n",
      "Epoch 24/100\n",
      "2188/2188 - 8s - 4ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6541 - val_loss: 0.6258 - learning_rate: 6.2500e-05\n",
      "Epoch 25/100\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6561 - loss: 0.6246 - val_auc: 0.6541 - val_loss: 0.6258 - learning_rate: 6.2500e-05\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2188/2188 - 6s - 3ms/step - auc: 0.6560 - loss: 0.6246 - val_auc: 0.6541 - val_loss: 0.6259 - learning_rate: 6.2500e-05\n",
      "Epoch 27/100\n",
      "2188/2188 - 7s - 3ms/step - auc: 0.6561 - loss: 0.6245 - val_auc: 0.6541 - val_loss: 0.6259 - learning_rate: 3.1250e-05\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 5 AUC: 0.65422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "FOLDS = 5\n",
    "kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "pred = np.zeros(len(test))\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(train, train[TARGET])):\n",
    "\n",
    "    print(f\"\\n{'#'*28}\")\n",
    "    print(f\"{'#'*10} Fold {i+1} {'#'*10}\")\n",
    "    print(f\"{'#'*28}\")\n",
    "\n",
    "    # SPLIT\n",
    "    X_train = train.loc[train_idx, FEATURES].copy()\n",
    "    y_train = train.loc[train_idx, TARGET].values\n",
    "\n",
    "    X_valid = train.loc[valid_idx, FEATURES].copy()\n",
    "    y_valid = train.loc[valid_idx, TARGET].values\n",
    "\n",
    "    X_test = test[FEATURES].copy()\n",
    "\n",
    "    # NORMALIZATION (numeric only assumed)\n",
    "    norm_cols = FEATURES\n",
    "    means = X_train[norm_cols].mean()\n",
    "    stds = X_train[norm_cols].std().replace(0, 1)\n",
    "\n",
    "    X_train[norm_cols] = (X_train[norm_cols] - means) / stds\n",
    "    X_valid[norm_cols] = (X_valid[norm_cols] - means) / stds\n",
    "    X_test[norm_cols] = (X_test[norm_cols] - means) / stds\n",
    "\n",
    "    # MODEL\n",
    "    K.clear_session()\n",
    "    model = build_model(X_train.shape[1])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.AUC(curve=\"ROC\")]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=make_callbacks(),\n",
    "        batch_size=256,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # PREDICTIONS\n",
    "    oof[valid_idx] = model.predict(X_valid, batch_size=512).ravel()\n",
    "    pred += model.predict(X_test, batch_size=512).ravel()\n",
    "\n",
    "    fold_auc = roc_auc_score(y_valid, oof[valid_idx])\n",
    "    print(f\"Fold {i+1} AUC: {fold_auc:.5f}\")\n",
    "\n",
    "pred /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e64c44ec-694d-4edb-8fdd-9850be82ae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.6538628354277897\n"
     ]
    }
   ],
   "source": [
    "cv_auc = roc_auc_score(train[TARGET], oof)\n",
    "print(\"CV AUC:\", cv_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8bcbc6-a0e2-410d-8e87-c5fae60119af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700000</td>\n",
       "      <td>0.608570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700001</td>\n",
       "      <td>0.644877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700002</td>\n",
       "      <td>0.696341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700003</td>\n",
       "      <td>0.626720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700004</td>\n",
       "      <td>0.869465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     label\n",
       "0  700000  0.608570\n",
       "1  700001  0.644877\n",
       "2  700002  0.696341\n",
       "3  700003  0.626720\n",
       "4  700004  0.869465"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],      # or your index column\n",
    "    \"label\": pred          # predicted probability\n",
    "})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75efd527-49ac-4e3b-89aa-10e8005d51c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'activity',\n",
       " 'diet',\n",
       " 'sleep',\n",
       " 'screen',\n",
       " 'bmi',\n",
       " 'waist_to_hip_ratio',\n",
       " 'systolic_bp',\n",
       " 'diastolic_bp',\n",
       " 'heart_rate',\n",
       " 'cholesterol_total',\n",
       " 'hdl_cholesterol',\n",
       " 'ldl_cholesterol',\n",
       " 'triglycerides']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c034bfb-3df2-4af0-bcfc-188acd348225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>activity</th>\n",
       "      <th>diet</th>\n",
       "      <th>sleep</th>\n",
       "      <th>screen</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>180</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>265</td>\n",
       "      <td>76</td>\n",
       "      <td>189</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  activity  diet  sleep  screen   bmi  waist_to_hip_ratio  systolic_bp  \\\n",
       "0   35       180   4.8    8.0    12.0  18.0                0.75          110   \n",
       "\n",
       "   diastolic_bp  heart_rate  cholesterol_total  hdl_cholesterol  \\\n",
       "0            70          90                265               76   \n",
       "\n",
       "   ldl_cholesterol  triglycerides  \n",
       "0              189             88  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nina =  pd.read_csv(DATA_PATH / \"Diabetes Prediction Challenge\" / \"Nina.csv\")\n",
    "nina.rename(columns = ({\"alcohol_consumption_per_week\":\"alc\",'physical_activity_minutes_per_week':\"activity\", 'diet_score':\"diet\",\n",
    "                          'sleep_hours_per_day': \"sleep\", 'screen_time_hours_per_day':\"screen\", 'education_level':\"edu\",\n",
    "                           'income_level':\"inc\", 'smoking_status': \"smoke\", 'employment_status':\"empl\", 'family_history_diabetes': \"fam_his\",\n",
    "                          'hypertension_history': \"hyp_his\", 'cardiovascular_history': \"card_his\", 'diagnosed_diabetes': \"label\"} ), inplace = True)\n",
    "nina[FEATURES].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2fa647a-da11-4414-b1f8-63c7345b6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[35, 180, 4.8, 8.0, 12.0, 18.0, 0.75, 110, 70, 90,265, 76, 189,88 ]], dtype=np.float32)\n",
    "p = model.predict(x)[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e592726d-573c-4d53-9bad-5c76c5b6a560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.41547245)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ff70991-9a44-461a-a2d6-31f089e1a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def permutation_importance_mlp(model, X_val, y_val, metric=roc_auc_score, n_repeats=5):\n",
    "    baseline = metric(y_val, model.predict(X_val, batch_size=512).ravel())\n",
    "    importances = []\n",
    "\n",
    "    for col in X_val.columns:\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_perm = X_val.copy()\n",
    "            X_perm[col] = np.random.permutation(X_perm[col].values)\n",
    "            score = metric(y_val, model.predict(X_perm, batch_size=512).ravel())\n",
    "            scores.append(baseline - score)\n",
    "\n",
    "        importances.append(np.mean(scores))\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"feature\": X_val.columns,\n",
    "        \"perm_importance\": importances\n",
    "    }).sort_values(\"perm_importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90f4c6de-64ac-46fd-8730-9809c32402fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>perm_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>activity</td>\n",
       "      <td>0.061694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.051466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>triglycerides</td>\n",
       "      <td>0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bmi</td>\n",
       "      <td>0.005015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hdl_cholesterol</td>\n",
       "      <td>0.003220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diet</td>\n",
       "      <td>0.002559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ldl_cholesterol</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>heart_rate</td>\n",
       "      <td>0.001924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cholesterol_total</td>\n",
       "      <td>0.001631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>screen</td>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>waist_to_hip_ratio</td>\n",
       "      <td>0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>systolic_bp</td>\n",
       "      <td>0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diastolic_bp</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sleep</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  perm_importance\n",
       "1             activity         0.061694\n",
       "0                  age         0.051466\n",
       "13       triglycerides         0.006408\n",
       "5                  bmi         0.005015\n",
       "11     hdl_cholesterol         0.003220\n",
       "2                 diet         0.002559\n",
       "12     ldl_cholesterol         0.002310\n",
       "9           heart_rate         0.001924\n",
       "10   cholesterol_total         0.001631\n",
       "4               screen         0.001181\n",
       "6   waist_to_hip_ratio         0.000664\n",
       "7          systolic_bp         0.000532\n",
       "8         diastolic_bp         0.000206\n",
       "3                sleep         0.000026"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = permutation_importance_mlp(model, X_valid, y_valid)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cdb77-a0df-4696-a268-50d7862d83ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
